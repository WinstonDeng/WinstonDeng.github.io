(window.webpackJsonp=window.webpackJsonp||[]).push([[9],{327:function(e,n,r){},361:function(e,n,r){"use strict";r(327)},377:function(e,n,r){"use strict";r.r(n);r(361);var t=r(45),a=Object(t.a)({},(function(){var e=this,n=e.$createElement,r=e._self._c||n;return r("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[r("ProfileSection",{attrs:{frontmatter:e.$page.frontmatter}}),e._v(" "),r("ul",[r("li",[e._v("CSIG Member")])]),e._v(" "),r("h2",{attrs:{id:"about-me"}},[e._v("About Me")]),e._v(" "),r("p",[e._v("I'm currently an AI Researcher & Engineer & TPM in "),r("a",{attrs:{href:"https://www.stepfun.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("StepFun"),r("OutboundLink")],1),e._v(", focusing on Agentic Model, working with "),r("a",{attrs:{href:"https://scholar.google.com/citations?user=tAAjbqgAAAAJ&hl=zh-CN&oi=ao",target:"_blank",rel:"noopener noreferrer"}},[e._v("Binxing Jiao"),r("OutboundLink")],1),e._v(" and "),r("a",{attrs:{href:"https://scholar.google.com/citations?hl=zh-CN&user=hJ-VrrIAAAAJ",target:"_blank",rel:"noopener noreferrer"}},[e._v("Zheng Ge"),r("OutboundLink")],1),e._v(". Before that I served as R&D Engineer in "),r("a",{attrs:{href:"https://www.momenta.cn/en/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Momenta"),r("OutboundLink")],1),e._v(", working on perception group of MSD (Momenta Self-Driving).")]),e._v(" "),r("p",[e._v("I got my Master's degree and Bachelor's degree in the School of Informatics at Xiamen University. Especially, I spent wonderful time from 2019 to 2023 in the "),r("a",{attrs:{href:"https://vcg.xmu.edu.cn/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Visual Computing and Graphics Lab"),r("OutboundLink")],1),e._v(", supervised by associate professor "),r("a",{attrs:{href:"http://mingzeng.xyz/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Ming Zeng"),r("OutboundLink")],1),e._v(". In 2022.6 -2022.9, I served as a virutal human research intern at "),r("a",{attrs:{href:"https://fuxivirtualhuman.github.io/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Virtual Human Group"),r("OutboundLink")],1),e._v(" of "),r("a",{attrs:{href:"https://fuxi.163.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("NetEase Fuxi AI Lab"),r("OutboundLink")],1),e._v(", working with "),r("a",{attrs:{href:"https://scholar.google.com/citations?user=FGRtKVoAAAAJ&hl=zh-CN&oi=ao",target:"_blank",rel:"noopener noreferrer"}},[e._v("Zhimeng Zhang"),r("OutboundLink")],1),e._v(" and "),r("a",{attrs:{href:"https://scholar.google.com/citations?hl=zh-CN&user=T9Vd-rcAAAAJ&view_op=list_works&sortby=pubdate",target:"_blank",rel:"noopener noreferrer"}},[e._v("Yu Ding"),r("OutboundLink")],1),e._v(".")]),e._v(" "),r("p",[e._v("My research interests lie at Computer Vision and Multi-modality LLM. I'm particularly interested in the areas of human-centric perception (pose estimation, restruction), generation and animation (speech audio or natural language driven).")]),e._v(" "),r("h2",{attrs:{id:"news"}},[e._v("News")]),e._v(" "),r("ul",[r("li",[e._v("[Oct. 2023] Our work on 3D Human Reconstruction has been accepted by Graphical Models.")]),e._v(" "),r("li",[e._v("[Sep. 2023] Our two National Invention Patents from China have been officially granted.")]),e._v(" "),r("li",[e._v("[Nov. 2022] Our work on singing head generation has been accepted by CVM2023 and CVMJ.")]),e._v(" "),r("li",[e._v("[Nov. 2022] Our work on talking head generation has been accepted by AAAI2023.")]),e._v(" "),r("li",[e._v("[Oct. 2022] I and my roommate "),r("a",{attrs:{href:"https://yinglinzheng.netlify.app/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Yinglin Zheng"),r("OutboundLink")],1),e._v(" won the National Scholarship for Graduate Students at the same time.")]),e._v(" "),r("li",[e._v("[Aug. 2022] Our work on talking head generation has been submitted to AAAI2023.")]),e._v(" "),r("li",[e._v("[Apr. 2022] Our work on multi-person pose estimation has been accepted by IJCAI2022.")]),e._v(" "),r("li",[e._v("[Mar. 2021] Our work on maksed face revealing is accepted by ICME 2021 as oral presentation.")]),e._v(" "),r("li",[e._v("[Feb. 2021] My "),r("a",{attrs:{href:"https://mp.weixin.qq.com/s/PNcclVdReiay5LXvlgMEyA",target:"_blank",rel:"noopener noreferrer"}},[e._v("zhihu survey on human pose"),r("OutboundLink")],1),e._v(" is re-tweeted by several well-known AI WeChat accounts.")]),e._v(" "),r("li",[e._v("[Oct. 2020] Our work on human pose estimation is accepted by PRCV 2020.")])]),e._v(" "),r("h2",{attrs:{id:"some-of-my-paper-co-authors"}},[e._v("Some of my paper co-authors")]),e._v(" "),r("p",[r("a",{attrs:{href:"http://mingzeng.xyz/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Ming Zeng"),r("OutboundLink")],1),e._v(", Associate Professor at School of Informatics, Xiamen University "),r("br"),e._v(" "),r("a",{attrs:{href:"https://yinglinzheng.netlify.app/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Yinglin Zheng"),r("OutboundLink")],1),e._v(", Research Intern at Visual Computing Group, Microsoft Research Asia (MSRA) "),r("br"),e._v(" "),r("a",{attrs:{href:"https://github.com/JPlin",target:"_blank",rel:"noopener noreferrer"}},[e._v("Jinpeng Lin"),r("OutboundLink")],1),e._v(", Researcher at AlibabaGroup "),r("br")]),e._v(" "),r("h2",{attrs:{id:"publications"}},[e._v("Publications")]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"https://ars.els-cdn.com/content/image/1-s2.0-S1524070323000371-ga1_lrg.jpg"}},[r("p",[e._v("Vertex position estimation with spatial–temporal transformer for 3D human reconstruction")]),e._v(" "),r("p",[e._v("Xiangjun Zhang, Yinglin Zheng, "),r("strong",[e._v("Wenjin Deng")]),e._v(", Qifeng Dai, Yuxin Lin, Wangzheng Shi, Ming Zeng")]),e._v(" "),r("p",[e._v("2023, Graphical Models")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://www.sciencedirect.com/science/article/pii/S1524070323000371",target:"_blank",rel:"noopener noreferrer"}},[e._v("Paper"),r("OutboundLink")],1)])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/musicface.png"}},[r("p",[e._v("MusicFace: Music-driven Expressive Singing Face Synthesis")]),e._v(" "),r("p",[e._v("Pengfei Liu, "),r("strong",[e._v("Wenjin Deng")]),e._v(", Hengda Li, Jintai Wang, Yinglin Zheng, Yiwei Ding, Xiaohu Guo, Ming Zeng")]),e._v(" "),r("p",[e._v("2022, The Computational Visual Media Conference (CVM2023)")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://arxiv.org/pdf/2303.14044.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Paper"),r("OutboundLink")],1),e._v(" "),r("a",{attrs:{href:"https://vcg.xmu.edu.cn/datasets/singingface/index.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("Data"),r("OutboundLink")],1)])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/DINet.png"}},[r("p",[e._v("DINet: Deformation Inpainting Network for Realistic Face Visually Dubbing on High Resolution Video")]),e._v(" "),r("p",[e._v("Zhimeng Zhang*, Zhipeng Hu*, "),r("strong",[e._v("Wenjin Deng")]),e._v("*, Changjie Fan, Tangjie Lv, Yu Ding*")]),e._v(" "),r("p",[e._v("2022, Thirty-Seventh AAAI Conference on Artificial Intelligence. (AAAI2023)")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://fuxivirtualhuman.github.io/pdf/AAAI2023_FaceDubbing.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("paper"),r("OutboundLink")],1),e._v(" "),r("a",{attrs:{href:"https://github.com/MRzzm/DINet",target:"_blank",rel:"noopener noreferrer"}},[e._v("Code"),r("OutboundLink")],1)])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"https://s1.ax1x.com/2022/04/21/LyGJKK.png"}},[r("p",[e._v("I^2R-Net: Intra- and Inter-Human Relation Network for Multi-Person Pose Estimation")]),e._v(" "),r("p",[e._v("Yiwei Ding*, "),r("strong",[e._v("Wenjin Deng")]),e._v("*, Yinglin Zheng, Pengfei Liu, Jianmin Bao, Meihong Wang, Xuan Cheng, Ming Zeng, Dong Chen")]),e._v(" "),r("p",[e._v("2022, The 31st International Joint Conference on Artificial Intelligence (IJCAI2022)")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://arxiv.org/pdf/2206.10892.pdf",target:"_blank",rel:"noopener noreferrer"}},[e._v("Paper"),r("OutboundLink")],1),e._v(" "),r("a",{attrs:{href:"https://github.com/leijue222/Intra-and-Inter-Human-Relation-Network-for-MPEE",target:"_blank",rel:"noopener noreferrer"}},[e._v("Code"),r("OutboundLink")],1)])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/projects/contrable.png"}},[r("p",[e._v("Controllable Facial Caricaturization with Localized Deformation and Personalized Semantic Attentions")]),e._v(" "),r("p",[e._v("Ming Zeng, Yinglin Zheng, Jinpeng Lin,  Xuan Cheng, Jing Liao, Zizhao Wu, "),r("strong",[e._v("Wenjin Deng")])]),e._v(" "),r("p",[e._v("2021, IEEE Transactions on Multimedia (TMM2021).")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://ieeexplore.ieee.org/document/9535294",target:"_blank",rel:"noopener noreferrer"}},[e._v("Link"),r("OutboundLink")],1)])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/projects/mask_face.png"}},[r("p",[e._v("Real-time Masked Face Revealing for Video Conference")]),e._v(" "),r("p",[e._v("Jinpeng Lin, Pengfei Liu, Yinglin Zheng, "),r("strong",[e._v("Wenjin Deng")]),e._v(", Ming Zeng")]),e._v(" "),r("p",[e._v("2021, IEEE International Conference on Multimedia and Expo (ICME2021), Oral presentation.")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://ieeexplore.ieee.org/document/9428117",target:"_blank",rel:"noopener noreferrer"}},[e._v("Link"),r("OutboundLink")],1)])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/projects/vh3d.png"}},[r("p",[e._v("VH3D-LSFM:Video-based Human 3D Pose Estimation with Long-term and Short-term Pose Fusion Mechanism")]),e._v(" "),r("p",[r("strong",[e._v("Wenjin Deng")]),e._v(", Yinglin Zheng, Hui Li, Xianwei Wang, Zizhao Wu, Ming Zeng")]),e._v(" "),r("p",[e._v("2020, Chinese Conference on Pattern Recognition and Computer Vision (PRCV2020)")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://link.springer.com/chapter/10.1007/978-3-030-60633-6_49",target:"_blank",rel:"noopener noreferrer"}},[e._v("Link"),r("OutboundLink")],1)])]),e._v(" "),r("h2",{attrs:{id:"patents-and-copyrights"}},[e._v("Patents and Copyrights")]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true"}},[r("ul",[r("li",[e._v("[中国国家发明专利] CN202111117800.8 一种感知环境的语音驱动虚拟人姿态合成方法 （已授权）")])]),e._v(" "),r("p",[e._v("曾鸣;"),r("strong",[e._v("邓文晋")]),e._v(";丁艺伟;刘鹏飞")]),e._v(" "),r("ul",[r("li",[e._v("[中国国家发明专利] CN202011092625.7 一种利用长短期信息融合的视频三维人体姿态估计算法 （已授权）")])]),e._v(" "),r("p",[e._v("曾鸣;"),r("strong",[e._v("邓文晋")])]),e._v(" "),r("ul",[r("li",[e._v("[中国国家发明专利] CN202110750794.3 一种利用语音信息的实时视频人脸区域时空一致合成方法 （已授权）")])]),e._v(" "),r("p",[e._v("曾鸣;刘鹏飞;"),r("strong",[e._v("邓文晋")])]),e._v(" "),r("ul",[r("li",[e._v("[中国国家发明专利] CN202011408727.5 一种增强医患相互信任减少医患矛盾评估预警系统 （已授权）")])]),e._v(" "),r("p",[e._v("赵一麟;曾鸣;"),r("strong",[e._v("邓文晋")]),e._v(";刘秋松;张红建;潘恒;丁艺伟;周旭;郭鹏;周媛媛;刘凤武")]),e._v(" "),r("ul",[r("li",[e._v("[软件著作权] 2019SR0447844 智能交互健身系统 （已授权）")])]),e._v(" "),r("p",[e._v("曾鸣,周熙盟,黄译嶙,陈梓豪,"),r("strong",[e._v("邓文晋")])])]),e._v(" "),r("h2",{attrs:{id:"projects"}},[e._v("Projects")]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/projects/case.png"}},[r("p",[e._v("A management system for case workflow")]),e._v(" "),r("p",[e._v("Java Backend: "),r("strong",[e._v("Wenjin Deng")]),e._v(", "),r("a",{attrs:{href:"https://github.com/BlacksLiu",target:"_blank",rel:"noopener noreferrer"}},[e._v("Pengfei Liu"),r("OutboundLink")],1)]),e._v(" "),r("p",[e._v("H5 frontend: "),r("a",{attrs:{href:"https://github.com/leijue222",target:"_blank",rel:"noopener noreferrer"}},[e._v("Yiwei Ding"),r("OutboundLink")],1),e._v(", "),r("strong",[e._v("Wenjin Deng")])]),e._v(" "),r("p",[e._v("2021")])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/projects/watermeter.png"}},[r("p",[e._v("Watermeter Reader Autonomous System for paper "),r("em",[e._v("Image-Based Automatic Watermeter Reading under Challenging Environments")])]),e._v(" "),r("p",[e._v("Java Backend: "),r("strong",[e._v("Wenjin Deng")]),e._v(", Jian Wang")]),e._v(" "),r("p",[e._v("H5 frontend: "),r("a",{attrs:{href:"https://github.com/leijue222",target:"_blank",rel:"noopener noreferrer"}},[e._v("Yiwei Ding"),r("OutboundLink")],1)]),e._v(" "),r("p",[e._v("2020")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://www.mdpi.com/1424-8220/21/2/434",target:"_blank",rel:"noopener noreferrer"}},[e._v("Paper Link"),r("OutboundLink")],1)])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/projects/iFit.png"}},[r("p",[e._v("AI fitness coach in web(PC/Mobile) using our Human Pose Estimation Network. Benefit from our design, it infers well pose on user's local device with 25fps.")]),e._v(" "),r("p",[e._v("Human Pose Estimation Algorithm & Website: "),r("a",{attrs:{href:"https://github.com/sppleHao",target:"_blank",rel:"noopener noreferrer"}},[e._v("Zihao Chen"),r("OutboundLink")],1),e._v(", "),r("strong",[e._v("Wenjin Deng")])]),e._v(" "),r("p",[e._v("Team: Ximeng Zhou, "),r("a",{attrs:{href:"https://github.com/sppleHao",target:"_blank",rel:"noopener noreferrer"}},[e._v("Zihao Chen"),r("OutboundLink")],1),e._v(", "),r("strong",[e._v("Wenjin Deng")]),e._v(", Yilin Huang")]),e._v(" "),r("p",[e._v("2018.08-2019.5")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://www.sohu.com/a/315247559_685340",target:"_blank",rel:"noopener noreferrer"}},[e._v("Media Report"),r("OutboundLink")],1)])]),e._v(" "),r("ProjectCard",{attrs:{hideBorder:"true",image:"/projects/ooad.png"}},[r("p",[e._v("A course system in web(PC/Mobile) using Springboot and VUE.")]),e._v(" "),r("p",[e._v("Java Backend: "),r("a",{attrs:{href:"https://github.com/17Wang",target:"_blank",rel:"noopener noreferrer"}},[e._v("Shiqi Wang"),r("OutboundLink")],1),e._v(", "),r("strong",[e._v("Wenjin Deng")])]),e._v(" "),r("p",[e._v("H5 frontend: Tianyu Su, "),r("a",{attrs:{href:"https://github.com/sppleHao",target:"_blank",rel:"noopener noreferrer"}},[e._v("Zihao Chen"),r("OutboundLink")],1)]),e._v(" "),r("p",[e._v("2018.11-2019.1")]),e._v(" "),r("p",[r("a",{attrs:{href:"https://github.com/OOAD2-3/RBS",target:"_blank",rel:"noopener noreferrer"}},[e._v("Project Link"),r("OutboundLink")],1)])]),e._v(" "),r("h2",{attrs:{id:"awards-honors"}},[e._v("Awards & Honors")]),e._v(" "),r("ul",[r("li",[e._v("National Scholarship for Graduate Students, Xiamen University, China, 2022")]),e._v(" "),r("li",[e._v("Cho Tak Wong Scholarship, Xiamen University, China, 2021")]),e._v(" "),r("li",[r("strong",[e._v("Outstanding prize (1st place)")]),e._v(' of the 12nd "Intel Cup" national undergraduate software innovation competition, Shanghai, China, 2019.')])]),e._v(" "),r("h2",{attrs:{id:"education"}},[e._v("Education")]),e._v(" "),r("ul",[r("li",[r("p",[r("strong",[e._v("School of Informatics, Xiamen University, M.S.")]),e._v(" "),r("br"),e._v("\nSept. 2020 - Jun. 2023")])]),e._v(" "),r("li",[r("p",[r("strong",[e._v("School of Informatics, Xiamen University, B.S.")]),e._v(" "),r("br"),e._v("\nSept. 2016 - Jun. 2020")])])]),e._v(" "),r("h2",{attrs:{id:"thanks"}},[e._v("Thanks")]),e._v(" "),r("p",[e._v("Great thanks to my friend "),r("a",{attrs:{href:"https://yinglinzheng.netlify.app/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Yinglin Zheng"),r("OutboundLink")],1),e._v(".\n")]),e._v(" "),r("a",{attrs:{href:"http://www.easycounter.com/"}},[r("img",{attrs:{src:"http://www.easycounter.com/counter.php?whiteair",border:"0",alt:"stats counter"}})])],1)}),[],!1,null,null,null);n.default=a.exports}}]);